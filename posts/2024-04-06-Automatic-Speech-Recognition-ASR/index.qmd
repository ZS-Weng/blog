---
title: "Exploring Meeting Transcription with Whisper"
date: "2024-04-06"
date-modified: "2024-04-06"
categories: [ASR, Automatic Speech Recognition, AI, Machine Learning, Transformer]
image: "speech_transcribe.jpg"
priority: 3
draft: True
---

## Introduction

![Image Generated by DallE3 with the prompt speech transcription](speech_transcribe.jpg)

In a recent engagement with a team that provides secretariat service, there is an opportunity to optimize the existing process of creating meeting minutes. In the current context there is a significant time spent in listening to recorded meeting captured on a voice recorder to ensure comprehensiveness of the points captured.

At some of these offline meetings, confidential issues and sensitive data are often shared. While recording these discussions is necessary for reference, sharing such recordings over the cloud or with third-party transcription services poses security risks. Leakage of confidential information could have severe consequences. As such, we decided to experiment with a local implementation rather than services available in the Cloud. 

Based on our initial exploration of the pre-trained open source models available on Hugging Face Hub, we find that models from the Whisper family can be easily setup and has a high accuracy of transcription. We refer to the comparison of different Hugging Face models at their [leaderboard page](https://huggingface.co/spaces/hf-audio/open_asr_leaderboard)


## Initial Setup of ffmpeg

In order to use the Whisper family of transformer models, there is a need to install ffmpeg first. The steps to setup ffmpeg which I found most straightforward are as follows:

1. Download installation package from the official site <https://ffmpeg.org/download.html>
2. Follow the guide in this online article to setup ffmpeg <https://www.wikihow.com/Install-FFmpeg-on-Windows>
3. Create a new environment for installation just to be safe
4. Install the following packages:
    - pip install ffmpeg <https://pypi.org/project/ffmpeg/>
    - pip install python-ffmpeg <https://pypi.org/project/python-ffmpeg/>

## Setting up Pytorch, HuggingFace and loading the pre-trained transformers model



## Transcribe the audio


## Next Steps


## References

- Models evaluation: https://huggingface.co/learn/audio-course/en/chapter5/evaluation